<!DOCTYPE html>
<html>
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-7LXHS2PFB5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-7LXHS2PFB5');
  </script>
  
  <meta charset="utf-8">
  <meta name="description"
        content="OTSeg: Multi-prompt Sinkhorn Attention for Zero-Shot Semantic Segmentation">
  <meta name="keywords" content="Zero-Shot, Optimal Transprot">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title> OTSeg: Multi-prompt Sinkhorn Attention for Zero-Shot Semantic Segmentation</title>
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./fig/otseg2.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <!-- <div class="navbar-menu"> -->
    <!-- <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://sites.google.com/view/kwanyoung-kim/?pli=1">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a> -->

      <!-- <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://github.com/cubeyoung/TA-VAAL">
            TA-VAAL (CVPR 2021)
          </a>          
          <a class="navbar-item" href="https://arxiv.org/pdf/2106.07009.pdf">
            Noise2Score (NeurIPS 2021)
          </a>
          <a class="navbar-item" href="https://arxiv.org/abs/2112.03696">
            NoiseAdap2Score (CVPR 2022)
          </a>          
          <a class="navbar-item" href="https://arxiv.org/abs/2104.05892">
            AdaINSeg (ECCV 2022)
          </a>          
          <a class="navbar-item" href="https://arxiv.org/pdf/2209.14566.pdf">
            DARL (ICLR 2023)
          </a>
        </div> -->
      <!-- </div>
    </div> -->
<!-- 
  </div>
</nav> --> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">OTSeg: Multi-prompt Sinkhorn Attention for Zero-Shot Semantic Segmentation</h1>
          <div class="is-size-4 publication-authors">
            <span class="author-block">
              <a href="https://sites.google.com/view/kwanyoung-kim/?pli=1">Kwanyoung Kim</a><sup>1*</sup>,</span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/yujin-oh-971137104/">Yujin Oh</a><sup>2*</sup>,</span>
            <span class="author-block">
              <a href="https://bispl.weebly.com/">Jong Chul Ye</a><sup>1</sup>,
            </span>
            <!-- <span class="author-block">
              Anonymous Authors</span> -->
          </div>
          <div class="is-size-5 publication-authors">            
            <span class="author-block"><sup>1</sup>Graduate School of AI, KAIST,</span> <sup>2</sup>Harvard Medical School & MGH
          </div>
          <div class="is-size-5 publication-authors">            
            <span class="author-block"><sup>*</sup>Equal contribution</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2403.14183"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2403.14183"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/cubeyoung/OTSeg"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <span class="link-block">
                <a href="https://www.linkedin.com/in/kwanyoung-kim-2a39b41b3/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-linkedin"></i>
                  </span>
                  <span>Linkedin</span>
                  </a>
              </span>

            </div>
            <div class="is-size-3 publication-authors">            
              <span class="author-block"><span style="color:#33CAFF;font-weight:bold;">ECCV 2024</span></span> 
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- main Figure. -->
    <div class="column">
        <h2 class="title is-3"></h2>
        <div class="columns is-centered">
          <div class="column content">
            <img src="./fig/score.png" 
            class="figure1"
            alt="figure1_image."/>
            <!-- <video id="teaser" autoplay muted loop playsinline height="100%">
            <source src="./fig/Vi"
                    type="video/mp4">
            </video>                  -->
          </div>
        </div>
    </div>
    <!--/ main Figure. -->    
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            The recent success of CLIP has demonstrated promising results in zero-shot semantic segmentation by transferring muiltimodal knowledge to pixel-level classification. 
            However, leveraging pre-trained CLIP knowledge to closely align text embeddings with pixel embeddings still has limitations in existing approaches. 
            To address this issue, we propose <span style="color:#33CAFF;font-weight:bold;">OTSeg</span>, a novel multimodal attention mechanism aimed at enhancing the potential of multiple text prompts for matching associated pixel embeddings. 
            We first propose <span style="color:#33CAFF;font-weight:bold;"> Multi-Prompts Sinkhorn (MPS) based on the Optimal Transport (OT) algorithm</span>, which leads multiple text prompts to selectively focus on various semantic features within image pixels. 
            Moreover, inspired by the success of Sinkformers in unimodal settings, we introduce the extension of MPS, called <span style="color:#33CAFF;font-weight:bold;"> Multi-Prompts Sinkhorn Attention (MPSA) </span> , which effectively replaces cross-attention mechanisms within Transformer framework in multimodal settings. Through extensive experiments, we demonstrate that OTSeg achieves state-of-the-art (SOTA) performance with significant gains on Zero-Shot Semantic Segmentation (ZS3) tasks across three benchmark datasets.    
            
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <!-- Effectiveness of ZegOT. -->
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Overview of OTSeg for zero-shot semantic segmentation</h2>
          <p>
            (a) MPS path refines the score map using the <span style="color:#33CAFF;font-weight:bold;"> MPS</span> algorithm.
            (b) Decoder path involves the decoder output, which integrates the the <span style="color:#33CAFF;font-weight:bold;">Multi-Prompts Sinkhorn Attention (MPSA) </span>predictions.
            (c) During inference, OTSeg ensembles predictions from both paths with a balancing factor lambda.
           </p>
          <img src="./fig/main.jpg" vspace = 10 
          class="figure1"
          alt="figure1_image."/>
        </div>
      </div>
      <!--/ Effectiveness of ZegOT. -->
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <!-- Effectiveness of ZegOT. -->
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Effectiveness of OTSeg</h2>
          <p>
            While all the text prompt-related score maps are cohered without MPSA (white arrows), with MPSA within our proposed OTSeg+, each Score map is diversely activated
            (red arrows) to help the model segment each object sharply. The  <span style="background-color:yellow;font-weight:bold;">yellow</span> tag indicates seen classes, while the <span style="background-color:#33FF39;font-weight:bold;">green </span> tag indicates unseen classes.            
          </p>
          <img src="./fig/score_sup.jpg" vspace = 10 
          class="figure1"
          alt="figure1_image."/>
        </div>
      </div>
      <!--/ Effectiveness of ZegOT. -->
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

      <!-- Multi Prompt OT Solver (MPOT) -->
      <div class="column">
        <h2 class="title is-3">Introduce a Novel Attention Mechanism</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              (a) Cross-attention mechanism for multimodal settings. (b) Sinkformer self-attention mechanism for unimodal settings. (c) Our proposed Muti-Prompt Sinkhorn Attention (MPSA) for multimodal settings, which aims to optimally transport image pixel (M) to multiple text prompts (N).
              Our proposed MPSA <span style="color:#33CAFF;font-weight:bold;">integrated as plugin module in each transformer layer, and achieve optimal matching between multiple text embedding and pixel embedding </span>.
            </p>            
            <img src="./fig/OT-attention.png" vspace = 10 
            class="figure1"
            alt="figure1_image."/>
          </div>
        </div>
      </div>
  </div>
</section>
<section class="section">
  <div class="container is-max-desktop">
      <h2 class="title is-3">Quantitative Result of OTSeg</h2>
      <!-- Visual Effects. -->
      <div class="column">
        <div class="columns is-centered">
          <div class="column content">      
              <img src="./fig/table.png"
              class="score_map"
              alt="score_map_image."/>
          </div>
        </div>
      </div>          
</section>
<section class="section">
    <div class="container is-max-desktop">
        <h2 class="title is-3">Qualitative Result of OTSeg</h2>
        <!-- Visual Effects. -->
        <div class="column">
          <div class="columns is-centered">
            <div class="column content">
                <p>
                  The <span style="background-color:yellow;font-weight:bold;">yellow</span> tag indicates seen classes, while the
                  <span style="background-color:#33FF39;font-weight:bold;">green </span> tag indicates unseen classes. Our OTSeg segmentes semantic objectex most accurately of both seen and unseen objects compare to previous SOTA methods. 
                </p>            
                <img src="./fig/main_result.jpg"
                class="score_map"
                alt="score_map_image."/>
            </div>
          </div>
        </div>        
        <!--/ Visual Effects. -->
        <div class="column">
            <div class="columns is-centered">
              <div class="column content">     
                  <img src="./fig/supple.png"
                  class="segment_results"
                  alt="segment_reults_image."/>
              </div>
            </div>
        </div> 
    </div>       
</section>


<section class="section">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <img src="./fig/main_result.jpg" alt="Steve Image" />
        </div>
        <div class="item item-chair-tp">
          <img src="./fig/supple.png" alt="Chair TP Image" />
        </div>
      </div>
    </div>
  </div>
</section>



<div style="text-align: center;">
  <a href="https://hits.seeyoufarm.com"><img src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fcubeyoung.github.io%2Fzegot.github.io%2F&count_bg=%233DC8C4&title_bg=%2320AA9F&icon=&icon_color=%23E7E7E7&title=hits&edge_flat=false"/></a>
</div>
<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="https://github.com/cubeyoung" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
